# プレゼンテーション台本

> **対象スライド:** `docs/system-improvement-slides.html`
> **想定時間:** 30〜40分（質疑込み）
> **読み方:** 各スライドの「話すこと」をそのまま読めば発表できるように書いています。
> 専門用語が出るたびに【用語解説】で噛み砕いています。

---

## 共通の用語（最初に頭に入れておくと楽です）

| 用語 | ひとこと説明 |
|------|------------|
| **LLM** | 大規模言語モデル。ChatGPTの中身のようなAI。本システムではOpenAI GPT-4を使用 |
| **バックエンド** | サーバー側。ユーザーには見えない裏方の処理プログラム（Python） |
| **フロントエンド** | 画面側。ユーザーが直接見て操作するブラウザの画面（React/TypeScript） |
| **API** | プログラム同士が情報をやり取りする窓口。「この形式でデータを送ってくれたら、この形式で返すよ」という約束事 |
| **JSON** | データの書き方のルール。`{"名前": "太郎", "年齢": 30}` のような波括弧で囲む形式 |
| **ハードコード** | プログラムの中に値を直接書き込むこと。変更するにはプログラム自体を書き換える必要がある |

---

## スライド 1 — タイトル

### 話すこと

「本日は、車両トラブル診断AIチャットシステムの改善について報告いたします。

このシステムは、お客様が車のトラブルを入力すると、AIが一問一答形式で症状を聞き取り、原因の特定から対処法の案内、必要に応じてディーラー予約まで行うチャットシステムです。

今回の報告では、以前の仕組みにあった問題点を洗い出し、それをどう改善したかをご説明します。」

---

## スライド 2 — 目次

### 話すこと

「発表は4つのパートに分かれています。

- **Part 1** で、以前の問題点と改善後の設計を比較します
- **Part 2** で、問診がどういう流れで動いているかをご説明します
- **Part 3** で、安全に関わる機能——危険度の判定、マニュアルに載っていない不具合の検出、そしてPDFマニュアルをAIが読める形にする処理——をご説明します
- **Part 4** で、ユーザーが回答をやり直せる機能をご紹介し、最後にまとめます」

---

## スライド 3 — 以前の問題点

### 話すこと

「まず、以前のシステムにはどんな問題があったかです。

大きく3つの問題がありました。

**1つ目は、バックエンド側の用語変換辞書です。**

スライド左側のコードを見てください。`diagnostic_config.yaml` というファイルに、『エンジン』という言葉が来たら『エンジン内部異常（振動/異音）』に置き換える、というルールが書かれていました。」

【用語解説】**yaml（ヤムル）** — 設定ファイルの書き方の一つ。「エンジン: エンジン内部異常」のように、コロンで区切って書く。

「これの何が問題かというと、たとえばAIが『エンジンはかかっていますか？』と質問し、選択肢に『かかっている』『かかっていない』を出そうとしたとします。ところが、『かかっていない』という文字列の中に『エンジン』が含まれているだけで、強制的に『エンジン内部異常（振動/異音）』に書き換えられてしまっていました。はい/いいえで答えたい質問に、まったく関係ない選択肢が出てしまうわけです。

**2つ目は、フロントエンド側にも同じ辞書が存在していたことです。**

右側を見てください。バックエンドで一度変換されたあと、画面を表示するプログラム側にも30個もの同じ変換ルールが書かれていて、さらにもう一度変換していました。つまり二重変換です。AIがどれだけ適切な選択肢を返しても、表示される頃には全く違うものになっていました。

**3つ目は、同じ選択肢が重複して表示される問題です。**

辞書で変換した結果、同じ文字列になってしまうことがあり、それをチェックする仕組みがなかったので、同じ選択肢が2つ3つ並ぶことがありました。」

---

## スライド 4 — 具体的な問題例

### 話すこと

「具体的にどうなっていたか、データの流れで見てみましょう。

左から右へ、データが流れていく図です。

**一番左**が、AIが出した本来の出力です。質問は『エンジンはかかっていますか？』、選択肢は『かかっている、かかっていない』——これは適切ですよね。

**次の箱**がバックエンド辞書です。ここで、"かかっていない"という文字列を見て、中に"エンジン"という文字が含まれていることを検出し、丸ごと"エンジン内部異常（振動/異音）"に書き換えます。

**その次**がフロントエンド辞書で、さらに同じことをやります。

**最後**にユーザーに表示されるのは、『エンジン内部異常（振動/異音）』が2つと『わからない』。もう何を聞かれているのかわかりません。」

【用語解説】**部分文字列マッチ（substring matching）** — 文字列の一部が含まれているかどうかで判定すること。「かかっていない」の中に「エンジン」は含まれていないので実際は「エンジンがかかっていない」のような文脈で発生。文脈を理解せず文字だけで判定するので、こうした誤作動が起きる。

---

## スライド 5 — Before / After 比較

### 話すこと

「では、それをどう直したかです。左が改善前、右が改善後です。

**改善前（左）** は、AIが選択肢を作る → バックエンドの辞書で書き換え → フロントエンドの辞書でまた書き換え → 重複チェックなしで表示、という流れでした。削除したファイルや関数が4つあります。これらは全て削除済みです。

**改善後（右）** は、3つの層で品質を管理する方式に変えました。

1つ目の層が **Schema（スキーマ）**。」

【用語解説】**Schema（スキーマ）** — 「データの形のルール」のことです。たとえば「選択肢は文字列のリストで返してね」「アクションはこの5種類のどれかにしてね」というルールをAIに渡します。AIはこのルールに従った形でしかデータを返せなくなります。

「2つ目の層が **Prompt（プロンプト）**。」

【用語解説】**Prompt（プロンプト）** — AIへの指示文のことです。「選択肢は質問の回答として適切なものだけにしてね」「エンジン内部異常みたいな質問の答えになっていないものは入れないでね」と具体例付きで指示します。

「3つ目の層が **App Code（アプリケーションコード）**。万が一AIが重複した選択肢を返した場合に、プログラム側で自動的に重複を取り除きます。

**重要なポイントは、辞書がゼロになったことです。** 以前は辞書を人間がメンテナンスしなければいけませんでしたが、今はAI自身が文脈を理解して、その場に合った選択肢を作ります。車種が増えても、辞書を更新する作業は一切不要です。」

---

## スライド 6 — 3層品質制御

### 話すこと

「この3層をもう少し詳しく説明します。

**Layer 1: Schema（型制約）**

スライド左のカードを見てください。コードに `"enum"` というものが書かれています。」

【用語解説】**enum（イナム/列挙型）制約** — 「この中のどれかしか選べません」というルールです。日本語で「列挙」と言います。たとえば信号機が「赤・黄・青」の3つしかないように、actionは`ask_question, clarify_term, provide_answer, escalate, spec_answer`の5つしか返せないというルールです。AIが「unknown」とか勝手な値を返すことが構造的にできなくなります。

【用語解説】**型制約** — 「このデータはこういう種類ですよ」という制限のことです。`"type": "string"` なら文字列、`"type": "number"` なら数値、`"type": ["array", "null"]` なら「配列（リスト）か、空っぽ（null）のどちらか」という意味です。

「つまり、AIがどんなに間違えようとしても、actionは5種類の値以外を返せませんし、選択肢は必ず文字列のリストか空っぽで返ってきます。型が違うデータが来ることはありえません。

**Layer 2: Prompt（意味的制約）**

真ん中のカードです。Schemaが『形のルール』だとすると、Promptは『意味のルール』です。
具体的なOKの例、NGの例を示して、AIに『こういう場合はこうして、こういうのはダメだよ』と指示しています。
たとえば『エンジンはかかっていますか？』に対しては『かかっている、かかっていない、たまにかかる』が正しい選択肢で、『エンジン内部異常』のような質問の答えではないものはNGだと明示しています。

**Layer 3: App Code（ガード）**

右のカードです。SchemaとPromptでほぼ問題は防げますが、念のためプログラム側でも最終チェックをします。具体的には、AIが返した選択肢のリストを上から見ていって、既に出てきた文字列と同じものがあればスキップする、という重複排除の処理です。加えて、『わからない』『自由に入力する』といった固定の選択肢を末尾に追加します。」

---

## スライド 7 — ステートマシン全体像

### 話すこと

「Part 2では、問診がどういう流れで進むかをご説明します。

画面の上に、左から右に8つの箱が並んでいます。これが診断の全体の流れで、**ステートマシン**と呼んでいます。」

【用語解説】**ステートマシン（状態遷移機）** — 「今どの段階にいるか」を管理する仕組みです。たとえば自動販売機は、「お金が入っていない → お金が入った → ボタンが押された → 商品を出す」と段階的に進みますよね。それと同じで、本システムは「車両選択 → 写真確認 → 症状入力 → …」と順番に段階を進んでいきます。今どの段階にいるかによって、プログラムがどう動くかが決まります。

「流れを簡単に説明すると：

1. **車両選択** — お客様がどの車かを選ぶ
2. **写真確認** — 車両の写真を確認
3. **症状入力** — お客様が自由に症状を入力する
4. **仕様確認** — 入力された症状が実は仕様通りの正常動作である可能性をチェック
5. **問診ループ** — ★がついているのがここです。AIが一問一答で深掘りしていく、システムの心臓部
6. **緊急度判定** — 危険度が高い場合に、来場の緊急度を最終評価
7. **予約案内** — ディーラーの来店予約やロードサービスの手配を案内
8. **完了**

下のカードに3つの分岐パターンがあります。通常フロー、緊急フロー（危険な症状の場合は問診を途中で打ち切って即対応）、仕様確認フロー（正常動作だった場合は問診不要）です。」

---

## スライド 8 — 問診ループの1ターン

### 話すこと

「では問診ループの中で、1回のやり取りでどんな処理が行われているかを見てみましょう。

左側に14の処理ステップが並んでいます。右側にその概要図があります。上から順に見ていきます。

**入力:** お客様の回答を記録し、今何ターン目かのカウントを1つ進めます。

**安全チェック:** お客様の入力文に危険なキーワードが含まれていないかチェックします。『ブレーキが効かない』のようなワードがあれば、AIの応答を待たずに即座に緊急対応に移ります。

**RAG検索:** お客様の症状に関連する車両マニュアルの情報をデータベースから検索します。」

【用語解説】**RAG（ラグ）** — Retrieval-Augmented Generation の略。「検索して補強した生成」という意味です。AIは元々マニュアルの内容を知りませんが、お客様の症状に関連するマニュアルの該当箇所をデータベースから引っ張ってきて、AIにその情報と一緒に考えてもらうことで、マニュアルに基づいた正確な回答ができるようになります。

「**LLM呼び出し:** ここが核心です。今までの会話履歴、マニュアル情報、ルール全てをAIに渡し、次に何をすべきかを構造化された形式で返してもらいます。これが先ほど説明したStructured Outputsです。

**ガード処理:** AIの返答に対して、同じ質問を繰り返していないか、無意味な応答をしていないか等のチェックをかけます。

**分岐:** AIの返答の種類に応じて処理が分かれます。`ask_question`なら質問を続ける。`provide_answer`なら原因と対処法を提示する。`escalate`なら緊急対応に移る、という具合です。」

---

## スライド 9 — Structured Outputs

### 話すこと

「Structured Outputsについてもう少し詳しく説明します。

これは、AIに『自由な文章ではなく、決められた形式のデータで答えてね』とお願いする仕組みです。」

【用語解説】**Structured Outputs（ストラクチャード・アウトプッツ）** — OpenAI社が提供する機能で、AIの返答を必ず決められたJSON形式に従わせることができます。通常AIは自由な文章を返しますが、この機能を使うと「action、message、urgency_flag…」のように、こちらが決めた項目を埋める形で返答します。形式が崩れることは構造的にありえません。

「左のカードに12個のフィールドが並んでいます。これがAIが毎回返す12項目です。

たとえば：
- **action** — AIが次にやることの種類。5つの中から1つ。
- **message** — ユーザーに見せるメッセージ本文
- **urgency_flag** — 危険度。none, low, medium, high, criticalの5段階
- **choices** — ユーザーに見せる選択肢。なければnull
- **confidence_to_answer** — 0.0〜1.0の数値で『もう原因がわかったので回答できる確信度』を表す。0.7以上になったら回答モードに切り替わる

右のカードが処理の流れです。

1. **schemas.py** というファイルで、12項目それぞれの型やルールを定義する
2. **prompts.py** で、各項目をどう判断すべきかAIに指示する
3. **openai_provider.py** で、OpenAIのAPIにSchemaを渡してAIを呼び出す
4. AIが必ずSchemaに従ったJSONを返す
5. **step_diagnosing.py** で、返ってきたJSONを読み取って次の処理を行う」

【用語解説】**パース（parse）** — データを読み取って、プログラムで扱える形に変換すること。AIから返ってきたJSON文字列を、プログラムが「actionはask_questionね、messageはこの文章ね」と個別の項目に分解して取り出す処理です。

---

## スライド 10 — 危険度判定

### 話すこと

「Part 3、安全機能に入ります。まずは危険度判定です。

本システムでは、お客様の症状がどのくらい危険かを **2段階** で判定しています。

**Stage 1: キーワード判定（即時）**

左のカードです。これはAIを使わず、ルールベースで判定します。」

【用語解説】**正規表現（regex）** — 文字列のパターンを検出する仕組みです。たとえば「ブレーキ」と「効かない」が近くにあるテキストを見つけるルールを書けます。AIに聞くより圧倒的に速く（0.1秒以内）判定できます。

「CRITICALレベルのキーワードは8個あります。ブレーキの故障、煙、火、オイル漏れ、ステアリングの異常、冷却水漏れ、オーバーヒートです。これらが検出されたら、AIの応答を待つことなく即座に緊急対応モードに切り替わります。人命に関わる可能性がある症状なので、0.1秒でも早く反応します。

HIGHレベルは警告灯や異音など、MEDIUMは燃費やエアコンなどです。

**Stage 2: LLM判定（詳細）**

右のカードです。キーワードだけでは判断しきれない複雑なケースを、AIに総合的に判定してもらいます。ここでもStructured Outputsを使って、5つの項目——危険度レベル、走行可否、来場緊急度、判断理由、推奨アクション——を返してもらいます。

最終的に、キーワード判定とAI判定の結果を比較して、**より危険度が高い方**を採用します。安全側に倒すためです。」

---

## スライド 11 — visit_urgency

### 話すこと

「危険度判定の結果として、`visit_urgency`（ビジットアージェンシー）という値が決まります。これは**お客様がいつディーラーに来場すべきか**を4段階で表すものです。

**immediate** — 今すぐ来場、またはロードサービスを呼ぶ。ブレーキ故障や煙が出ている場合です。この場合は運転してはいけないので `can_drive = false`、画面に赤い太字で『運転を中止してください』と表示されます。

**today** — 本日中に来場してください。警告灯が点灯しているような場合です。運転はできるけれど早めの対応が必要です。

**this_week** — 今週中に来場してください。燃費の悪化や軽い異音のような場合です。

**when_convenient** — ご都合の良い時にどうぞ。ワイパーの劣化など急ぎではない場合です。

ここで大事な設計ポイントがあります。`can_drive`（運転を続けていいか）と `visit_urgency`（いつ来場すべきか）は**別々の判定軸**です。たとえば警告灯が点灯している場合、運転は一応できる（can_drive = true）けれど、本日中に来場すべき（visit_urgency = today）——というケースがありえます。この2つを分けることで、より正確な案内ができています。」

---

## スライド 12 — マニュアル記載外検出

### 話すこと

「次に、マニュアルに載っていない不具合を検出する仕組みです。

左の図を見てください。流れは以下の通りです。

1. まず**RAG検索**で、お客様の症状に関連するマニュアル情報を検索します
2. AIがその検索結果とお客様の症状を照らし合わせて、**manual_coverage**という値を判定します
3. この判定は問診の各ターンで毎回行われ、更新されます

判定結果は3種類あります。

- **covered** — マニュアルに原因や対処法がしっかり書いてある。この場合は特に何も表示せず、通常通り問診を進めます。
- **partially_covered** — 関連する情報はマニュアルにあるけれど、まさにこの症状そのものの説明はない。グレーのバッジで『マニュアルに完全一致する情報はありません』と表示します。
- **not_covered** — マニュアルに該当する記載が一切ない。これは想定外の不具合の可能性があります。

not_coveredになった場合は自動的に3つの対応が発動します。
1. 危険度を自動で1段階引き上げる（たとえばlowならmediumに）
2. 黄色のバッジで『マニュアル記載外 — 想定外の不具合の可能性があります』と警告
3. 最終回答時に『ディーラーでの点検を推奨します』の一文を追加

マニュアルに載っていない症状は未知のリスクがあるため、安全側に倒す設計になっています。」

---

## スライド 13 — チャンキング（RAG前処理）

### 話すこと

「先ほどから何度か出てきたRAGの前処理、**チャンキング**について説明します。

そもそもAIがマニュアルの情報を参照するには、あらかじめPDFのマニュアルをデータベースに取り込んでおく必要があります。その取り込みの流れが左側のRAGパイプラインです。」

【用語解説】**パイプライン** — 処理が順番につながっている仕組みのこと。工場の組み立てラインのように、前の工程の出力が次の工程の入力になります。

「4つのステップがあります。

1. **PDF読込** — PDFファイルからページごとにテキストを取り出す
2. **チャンキング** — テキストを検索に適したサイズに分割する。ここが今日説明する部分です
3. **エンベディング** — 分割したテキストを数値の列（ベクトル）に変換する」

【用語解説】**エンベディング（embedding）** — テキストの意味を数値の列で表現すること。たとえば「ブレーキの異音」と「ブレーキから変な音がする」は文字は違いますが意味は近いですよね。エンベディングすると、似た意味の文は近い数値になるので、「意味が近いテキストを探す」ということができるようになります。

「4. **格納** — ベクトルをChromaDBというデータベースに保存する」

【用語解説】**ChromaDB（クロマDB）** — ベクトル検索に特化したデータベース。通常のデータベースは「この名前と一致するデータを探して」という完全一致検索ですが、ChromaDBは「この意味に近いテキストを探して」という類似度検索ができます。

「右側のカードに、チャンキングの工夫が書かれています。本システムでは一般的なチャンキングではなく、自動車マニュアルに特化した処理をしています。

1つ目は**安全情報の分離**。『警告』『危険』等のキーワードを含む段落は、他のテキストと混ぜずに独立した塊として切り出します。これにより、安全に関する注意事項が検索で確実にヒットします。

2つ目は**コンテンツ分類**。各塊を5つのタイプに自動分類します。warning（安全警告）、troubleshooting（トラブル対応）、procedure（操作手順）、specification（仕様）、general（その他）。

3つ目は**ノイズ除去**。目次ページやクイックガイドなど、診断には不要なページを自動検出して除外します。

4つ目は**セクション追跡**。『第3章 エンジン』のような章タイトルを検出し、各塊にどのセクションの情報かを記録します。」

【用語解説】**チャンキング（chunking）** — 長いテキストを短い塊（チャンク）に分割すること。マニュアル全体は何百ページもあって一度にAIに渡せないので、600文字程度の塊に切り分けます。検索のとき「この塊が一番関連がありそう」と見つけやすくなります。

---

## スライド 14 — コンテンツ分類の仕組み

### 話すこと

「チャンキングのコンテンツ分類について、もう少し掘り下げます。

左上のカードが安全キーワードのリストです。「警告」「危険」「火災」「爆発」など10個のキーワードがあり、**1つでもマッチすれば**即座にwarningタイプに分類されます。安全に関わる情報を絶対に見逃さないための最優先ルールです。

ただし注意点があって、『警告灯』はwarningには分類しません。『警告灯が点灯している』はトラブルシューティングの情報であって、安全警告そのものではないからです。この区別は自動的に行われます。

左下のカードが残り3タイプの判定方法です。ここでは**スコアリング方式**を使います。」

【用語解説】**スコアリング方式** — 各カテゴリに関連するキーワードが何個含まれているかを数え、一番多いカテゴリに分類する方法。たとえばあるテキストに「故障」「異音」「点検」があれば troubleshooting のスコアが3、「手順」「交換」があれば procedure のスコアが2。スコアが一番高い troubleshooting に分類されます。

「右側のフロー図がアルゴリズムの全体像です。入力テキストに対して、まず安全キーワードを確認。マッチがあればwarning。なければ3タイプのスコアを計算。全スコア0ならgeneral。そうでなければ最高スコアのタイプを採用します。

なぜこの設計かというと、自動車マニュアルでは安全警告が最も重要な情報です。お客様がタイヤ交換の手順を聞いているときに、『ジャッキアップ時に車体が落下する危険があります』という警告は絶対に伝えなければいけません。チャンキングの段階で安全情報を分離しておくことで、RAG検索時に危険な注意事項を見落とさないようにしています。」

---

## スライド 15 — やり直し機能

### 話すこと

「Part 4、やり直し機能です。

左上のカードで、なぜこの機能が必要かを説明しています。一問一答形式の問診では、途中でお客様が回答を間違えると、その後の診断が全て的外れになります。たとえば『エンジンはかかっていますか？』に『かかっている』と答えたけど、実は『かかっていない』だった場合。以前はチャットを最初からやり直すしかありませんでした。

解決策として**スナップショット方式**を採用しました。」

【用語解説】**スナップショット** — ある時点のシステムの状態を丸ごとコピーして保存したもの。ゲームの「セーブデータ」と同じ考え方です。問診の各ターンで、そのときのセッション情報（会話履歴、診断の進捗、判定結果など）をまるごとコピーして記録します。

「左下の図を見てください。Turn 1で1つ目のスナップショットを保存、Turn 2で2つ目…と各ターンの状態を保存していきます。お客様が『Turn 2をやり直したい』と言ったら、Turn 2時点のスナップショットを取り出して、その状態に戻します。Turn 2以降のスナップショットは削除されます。

右側に技術的な仕組みが書かれていますが、要点は：

- バックエンドでは、各ターンの開始時にセッション全体のコピーを保存する
- やり直し要求が来たら、指定されたターンのコピーからセッション状態を復元する
- フロントエンドでは、該当ターン以降のメッセージを画面から削除する

制約として、この機能は問診ステップ（DIAGNOSING）でのみ有効で、最大8ターン分のスナップショットを保持します。」

【用語解説】**セッション** — ユーザーがシステムを使い始めてから終了するまでの一連のやり取りのこと。セッション情報には、今どの車の話をしているか、問診が何ターン目か、今までの会話履歴は何か、など全ての状態が含まれます。

【用語解説】**インメモリ** — サーバーのメモリ（RAM）上に保存すること。データベースに書き込むよりも高速ですが、サーバーを再起動すると消えます。問診中のみ必要なスナップショットなので、この方式で十分です。

---

## スライド 16 — やり直し機能の操作フロー

### 話すこと

「ユーザーから見た操作フローを3ステップで示しています。

**Step 1（左）** — 通常の問診画面です。AIの質問とお客様の回答が交互に並んでいます。お客様の各回答の下に『やり直す』という小さなリンクが表示されています。

**Step 2（中央）** — お客様が1つ目の回答の『やり直す』を押した状態です。押した回答が黄色い枠でハイライトされ、それ以降のメッセージは薄くなっています。これらは削除される予定であることを示しています。

**Step 3（右）** — 巻き戻し完了です。AIの最初の質問だけが残り、お客様は改めて別の回答を入力できます。バックエンド側も、この時点の状態に完全に復元されているので、新しい回答に基づいた新しい問診が始まります。

このようにゲームの『セーブポイントに戻る』ような操作を、チャット上で自然に行えるようにしています。」

---

## スライド 17 — 画像選択カード（警告灯アイコン）

### 話すこと

「やり直し機能に続いて、もう一つのUX改善、**画像選択カード**をご紹介します。

問診で『ダッシュボードのどの警告灯が点灯していますか？』という質問が出ることがあります。この時、テキストボタンで『エンジン警告灯』『ABS警告灯』『TPMS警告灯』と並んでも、車に詳しくないお客様にとっては『TPMSって何？』となりかねません。

そこで、警告灯の種類をアイコン付きのカード形式で表示するようにしました。

**処理の仕組み**はシンプルです。

1. LLMがいつも通り質問と選択肢を生成します。この時点では普通のテキストです
2. バックエンドの後処理で、質問トピックに『警告灯』『ランプ』などのキーワードが含まれていれば、各選択肢のラベルから該当する警告灯のアイコンパスを付与します
3. フロントエンドがアイコン付きの選択肢を検出すると、自動的に3列のカードグリッドに切り替えて表示します

**大事な設計ポイントが3つあります。**

1つ目は、**LLMのスキーマは一切変更していない**こと。アイコンの付与はバックエンドの後処理で行うため、AI側の修正は不要です。新しい警告灯を追加したい場合は、辞書にキーワードとアイコンを追加するだけです。

2つ目は、**テキストボタンとの共存**。『わからない』や『自由入力』のようにアイコンがない選択肢は、カードグリッドの下に従来通りのテキストボタンとして配置されます。

3つ目は、**警告灯以外の質問には影響しない**こと。『異音の種類は？』のような質問では、トピック判定でヒットしないため、従来通りのテキストボタンがそのまま表示されます。」

---

## スライド 18 — 安全アーキテクチャの全体像

### 話すこと

「ここで、安全に関わる仕組みの全体像を整理します。本システムでは5つの層で多層防御を行っています。

**Layer 1 — キーワード緊急度:** 高速なルールベース判定。ブレーキ、煙、火等のCRITICALキーワードを即座に検出。

**Layer 2 — LLM緊急度評価:** AIによる総合判定。複雑な症状の組み合わせも理解できる。

**Layer 3 — マニュアル記載外検出:** マニュアルに載っていない症状を検出し、危険度を自動で引き上げる。

**Layer 4 — トピック逸脱検出:** AIが同じ質問を繰り返したり、診断と関係ない話題にそれることを防ぐ。

**Layer 5 — 重複排除・ガード:** 選択肢の重複除去や、意味のない応答の検出など。

下のカードに3つの原則をまとめています。

**即時遮断** — 危険なキーワードはAIを待たずに即座に対応。
**段階的引上げ** — マニュアルに記載がない症状は自動的に危険度を上げる。常に安全側に倒す。
**品質保証** — Schema、Prompt、App Codeの3層でAI出力の品質を保証する。」

【用語解説】**多層防御** — 1つの防御が突破されても、次の防御で止める、という考え方。空港のセキュリティが、チケット確認 → 手荷物検査 → ボディチェック → パスポート確認と何重にもなっているのと同じです。どれか1つが見逃しても、別の層が拾います。

---

## スライド 19 — まとめ

### 話すこと

「最後にまとめです。

**BEFORE（改善前）** は、ハードコード辞書による強制変換、二重辞書、文脈無視の変換、重複チェックなし、辞書のメンテナンスコスト、車種追加時の辞書更新——こうした問題がありました。取り消し線のついた項目は全て解消済みです。

**AFTER（改善後）** は、6つの改善を実現しました。

1. **ハードコード辞書ゼロ** — 変換辞書を全て削除。AIとRAGによる動的生成に完全移行。
2. **3層品質制御** — Schema、Prompt、App Codeの3つの層でAI出力の品質を保証。
3. **2段階危険度判定** — キーワードによる即時判定とAIによる詳細判定の2段階。
4. **マニュアル記載外検出** — マニュアルに載っていない症状を自動検出し、安全側に倒す。
5. **自動車特化チャンキング** — 安全情報を優先分離するマニュアル前処理。
6. **やり直し機能** — 回答ミスからワンボタンで復帰できるUX。
7. **画像選択カード** — 警告灯をアイコンで直感的に選択できるUI。

設計思想としては3つ。
**AI駆動** — 辞書ではなくAIが文脈を理解して生成。
**安全最優先** — 多層防御で危険を見逃さない。迷ったら安全側。
**メンテナンスフリー** — 車種追加はPDFをアップロードするだけ。辞書の更新作業は一切不要。

以上で発表を終わります。」

---

## スライド 20 — Thank You

### 話すこと

「ご清聴ありがとうございました。ご質問がありましたらお願いいたします。」

---

## 想定Q&A

### Q: AIが間違った選択肢を返すことはないのか？
**A:** 3層品質制御で防いでいます。Schemaで型の制約、Promptで意味の制約、App Codeで最終的な重複排除。完全にゼロにはできませんが、以前の辞書方式と比べると、AIは質問の文脈を理解した上で選択肢を作るため、不適切な選択肢が出る確率は大幅に下がっています。

### Q: マニュアルに載っていない新しい不具合にはどう対応するのか？
**A:** manual_coverage機能で「not_covered（記載なし）」と判定されます。その場合は自動的に危険度が1段階上がり、ディーラーでの点検を推奨するメッセージが表示されます。AIだけでは判断できない症状は、プロに見てもらうように誘導する設計です。

### Q: やり直し機能で、古いスナップショットが増えてメモリを圧迫しないか？
**A:** 最大8ターン分に制限しています。1スナップショットあたり約5KBなので、合計でも約40KB。インメモリ保存ですが問題ないサイズです。セッション終了時に全て破棄されます。

### Q: 新しい車種を追加するときに必要な作業は？
**A:** PDFのオーナーズマニュアルをアップロードするだけです。チャンキング処理が自動で分割・分類・ベクトル化してデータベースに格納します。辞書の更新やプログラムの変更は不要です。

### Q: CRITICALキーワードに該当しない危険な症状はどうなるのか？
**A:** Stage 2のLLM判定でカバーされます。キーワードに一致しなくても、AIが症状の内容を総合的に判断してhighやcriticalと判定できます。最終的に、キーワード判定とAI判定の高い方が採用されるので、どちらかが検出すれば対応されます。
